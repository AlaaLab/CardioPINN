{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Program for comparing the adjoint odeint method and the NN-interpolator method in two tasks:\n",
        "1. They are trained on a fixed synthetic input with the goal of finding optimal parameters yielding the true EF,\n",
        "2. They are trained on a synthetic dataset of 400 patients (randomly taken from the Echonet dataset) with the goal of learning to predict optimal circuit parameters yielding correct EFs for the patients.\n",
        "\n",
        "To run this code (which has been made in a Google Colab notebook), the following three files have to be saved in the Drive:\n",
        "- net_weights__weight.pt\n",
        "- input_450patients_echonet.pt\n",
        "- labels_450patients_echonet.pt.\n",
        "\n",
        "Summarized results: when the integration time is too high (e.g. 15 cardiac cycles) the odeint adjoint method takes extremely long times for only one iteration (several minutes, and often gets error due to stiffness, even when using 'euler' integration and low time step). On the other hand, if the integration time is low (eg 1 cardiac cycle) the predictions made by the odeint adjoint method are far from the correct ones since it takes 5-15 cardiac cycles of the simulation to reach the steady state."
      ],
      "metadata": {
        "id": "fu5ms6Q6vlXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "!pip3 install torchdiffeq\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "parser = argparse.ArgumentParser('ODE demo')\n",
        "\n",
        "parser.add_argument('--method', type=str, choices=['dopri5', 'adams'], default='dopri5')\n",
        "parser.add_argument('--data_size', type=int, default=1000) #size of true_y and pred_y and t (n of timepoints for the diff eq in odeint)\n",
        "parser.add_argument('--batch_time', type=int, default=10) #batch_t takes the first batch_time(=10) first elements of t\n",
        "parser.add_argument('--batch_size', type=int, default=1)\n",
        "parser.add_argument('--niters', type=int, default=2000)\n",
        "parser.add_argument('--test_freq', type=int, default=20)\n",
        "parser.add_argument('--viz', action='store_true')\n",
        "parser.add_argument('--gpu', type=int, default=0)\n",
        "parser.add_argument('--adjoint', action='store_true')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "from torchdiffeq import odeint_adjoint as odeint\n",
        "from scipy.integrate import odeint as odeint_standard\n",
        "\n",
        "device = torch.device('cuda:' + str(args.gpu) if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIeMMxStVIMO",
        "outputId": "1901876a-aefc-491b-8ad2-757ca2946d72"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.1.0+cu121)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3.0->torchdiffeq) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3.0->torchdiffeq) (2.1.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3.0->torchdiffeq) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pv loop simulator (and returns v_i):"
      ],
      "metadata": {
        "id": "eogGFjDpWL9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### ODE: for each t (here fixed), gives dy/dt as a function of y(t) at that t, so can be used for integrating the vector y over time\n",
        "#it is run for each t going from 0 to tmax\n",
        "def heart_ode(y, t, Rs, Rm, Ra, Rc, Ca, Cs, Cr, Ls, Emax, Emin, Tc):\n",
        "    x1, x2, x3, x4, x5 = y #here y is a vector of 5 values (not functions), at time t, used for getting (dy/dt)(t)\n",
        "    P_lv = Plv(x1,Emax,Emin,t,Tc)\n",
        "    dydt = [r(x2-P_lv)/Rm-r(P_lv-x4)/Ra, (x3-x2)/(Rs*Cr)-r(x2-P_lv)/(Cr*Rm), (x2-x3)/(Rs*Cs)+x5/Cs, -x5/Ca+r(P_lv-x4)/(Ca*Ra), (x4-x3-Rc*x5)/Ls]\n",
        "    return dydt\n",
        "\n",
        "def r(u):\n",
        "    return max(u, 0.)\n",
        "\n",
        "#returns Plv at time t using Elastance(t) and Vlv(t)-Vd=x1\n",
        "def Plv(x1, Emax, Emin, t, Tc):\n",
        "    return Elastance(Emax,Emin,t, Tc)*x1\n",
        "\n",
        "#returns Elastance(t)\n",
        "def Elastance(Emax,Emin,t, Tc):\n",
        "    t = t-int(t/Tc)*Tc #can remove this if only want 1st ED (and the 1st ES before)\n",
        "    tn = t/(0.2+0.15*Tc)\n",
        "    return (Emax-Emin)*1.55*(tn/0.7)**1.9/((tn/0.7)**1.9+1)*1/((tn/1.17)**21.9+1) + Emin\n",
        "\n",
        "def pvloop_simulator(Tc, start_v, Emax, Emin, Rm, Ra, Vd, N, plotloops, plotpressures, plotflow):\n",
        "    startp = 75.\n",
        "    Rs = 1.0\n",
        "    Rc = 0.0398\n",
        "    Ca = 0.08\n",
        "    Cs = 1.33\n",
        "    Cr = 4.400\n",
        "    Ls = 0.0005\n",
        "\n",
        "    start_pla = float(start_v*Elastance(Emax, Emin, 0, Tc))\n",
        "    start_pao = startp\n",
        "    start_pa = start_pao\n",
        "    start_qt = 0 #aortic flow is Q_T and is 0 at ED, also see Fig5 in simaan2008dynamical\n",
        "    y0 = [start_v, start_pla, start_pa, start_pao, start_qt]\n",
        "\n",
        "    t = np.linspace(0, Tc*N, int(60000*N)) #spaced numbers over interval (start, stop, number_of_steps), 60000 time instances for each heart cycle\n",
        "    #changed to 60000 for having integer positions for Tmax\n",
        "\n",
        "    sol = odeint_standard(heart_ode, y0, t, args = (Rs, Rm, Ra, Rc, Ca, Cs, Cr, Ls, Emax, Emin, Tc)) #t: list of values\n",
        "\n",
        "    result_Vlv = np.array(sol[:, 0]) + Vd\n",
        "    result_Plv = np.array([Plv(v, Emax, Emin, xi, Tc) for xi,v in zip(t,sol[:, 0])])\n",
        "\n",
        "    ved = sol[(N-1)*60000, 0] + Vd\n",
        "    ves = sol[200*int(60/Tc)+9000+(N-1)*60000, 0] + Vd # 0.2 s = ?. Tc s = 60000 -> 1 s = int(60000/Tc) -> x s = int( x * 60000/Tc)\n",
        "    ef = (ved-ves)/ved * 100.\n",
        "\n",
        "    X = [result_Vlv[(N-1)*60000 +12000], result_Vlv[(N-1)*60000 + 24000], result_Vlv[(N-1)*60000 +36000], result_Vlv[(N-1)*60000 +48000]] #input: volumes at times 0.2Tc, 0.4Tc, 0.6Tc, 0.8Tc = 18000, 30000, 48000\n",
        "\n",
        "    minv = min(result_Vlv[(N-1)*60000:N*60000-1])\n",
        "    minp = min(result_Plv[(N-1)*60000:N*60000-1])\n",
        "    maxp = max(result_Plv[(N-1)*60000:N*60000-1])\n",
        "\n",
        "    ved2 = sol[(N-1)*60000 - 1, 0] + Vd\n",
        "    isperiodic = 0\n",
        "    if (abs(ved-ved2) > 5.): isperiodic = 1\n",
        "\n",
        "    if plotloops:\n",
        "      plt.plot(result_Vlv[(N-2)*60000:(N)*60000], result_Plv[(N-2)*60000:N*60000])\n",
        "      plt.xlabel(\"LV volume (ml)\")\n",
        "      plt.ylabel(\"LV pressure (mmHg)\")\n",
        "      plt.show()\n",
        "\n",
        "    if plotpressures:\n",
        "      result_Pla = np.array(sol[:, 1])\n",
        "      result_Pa = np.array(sol[:, 2])\n",
        "      result_Pao = np.array(sol[:, 3])\n",
        "      plt.plot(t[(N-2)*60000:(N)*60000], result_Plv[(N-2)*60000:N*60000], label='LV P')\n",
        "      plt.plot(t[(N-2)*60000:(N)*60000], result_Pao[(N-2)*60000:N*60000], label='Aortic P')\n",
        "      plt.plot(t[(N-2)*60000:(N)*60000], result_Pa[(N-2)*60000:N*60000], label='Arterial P')\n",
        "      plt.plot(t[(N-2)*60000:(N)*60000], result_Pla[(N-2)*60000:N*60000], label='Left atrial P')\n",
        "      plt.xlabel(\"Time (s)\")\n",
        "      plt.ylabel(\"Pressure (mmHg)\")\n",
        "      plt.legend(loc='upper right', framealpha=1)\n",
        "      plt.show()\n",
        "\n",
        "    if plotflow:\n",
        "      result_Q = np.array(sol[:, 4])\n",
        "      plt.plot(t[(N-2)*60000:(N)*60000], result_Q[(N-2)*60000:N*60000])\n",
        "      plt.xlabel(\"Time (s)\")\n",
        "      plt.ylabel(\"Blood flow (ml/s)\")\n",
        "\n",
        "    return X, ved, ves, ef #, minv, minp, maxp, isperiodic"
      ],
      "metadata": {
        "id": "WzkFZeO_WQYW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Neural ODE-based model:"
      ],
      "metadata": {
        "id": "Q5VI_ZfagG0T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TqigCV-wUmSp"
      },
      "outputs": [],
      "source": [
        "## fixed parameters of the circuit:\n",
        "Rs = 1.0\n",
        "Rc = 0.0398\n",
        "Ca = 0.08\n",
        "Cs = 1.33\n",
        "Cr = 4.400\n",
        "Ls = 0.0005\n",
        "\n",
        "def makedirs(dirname):\n",
        "    if not os.path.exists(dirname):\n",
        "        os.makedirs(dirname)\n",
        "\n",
        "## normalizes the parameters to realistic ranges (intervals of validity: same as those used for creating the NN-interpolator)\n",
        "class Normalizer(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lower = torch.tensor([0.4, 0., 0.5, 0.02, 0.005, 0.0001, 4.], dtype=torch.float32)\n",
        "        self.upper = torch.tensor([1.7, 280., 3.5, 0.1, 0.1, 0.25, 25.], dtype=torch.float32)\n",
        "    def forward(self, inputs):\n",
        "        return torch.sigmoid(inputs) * (self.upper - self.lower) + self.lower\n",
        "\n",
        "class ODEFunc(nn.Module): #takes y, t and returns dydt = NN(y,t). NN: defined in self.net (NN: (y**3, t**3):2D->50->tanh->2D=dydt)\n",
        "    def __init__(self, tc, emax, emin, rm, ra, vd):\n",
        "        super(ODEFunc, self).__init__()\n",
        "        self.tc = tc\n",
        "        self.emax = emax\n",
        "        self.emin = emin\n",
        "        self.rm = rm\n",
        "        self.ra = ra\n",
        "        self.vd = vd\n",
        "\n",
        "    def forward(self, t, y):\n",
        "\n",
        "        global Rs, Rc, Cs, Cr, Ca, Ls\n",
        "        dydt = torch.zeros_like(y)\n",
        "\n",
        "        tn = ( t - int(t/self.tc) * self.tc ) / (0.2+0.15 * self.tc)\n",
        "        P_lv = ( (self.emax-self.emin)*1.55*(tn/0.7)**1.9/((tn/0.7)**1.9+1)*1/((tn/1.17)**21.9+1) + self.emin ) * y[0]\n",
        "\n",
        "        dydt[0] = torch.relu(y[1] - P_lv) / self.rm - torch.relu(P_lv - y[3]) / self.ra\n",
        "        dydt[1] = (y[2]-y[1]) / (Rs*Cr) - torch.relu(y[1]-P_lv) / (Cr*self.rm)\n",
        "        dydt[2] = (y[1]-y[2]) / (Rs*Cs) + y[4] / Cs\n",
        "        dydt[3] = - y[4] / Ca + torch.relu(P_lv-y[3]) / (Ca*self.ra)\n",
        "        dydt[4] = (y[3]-y[2]-Rc*y[4]) / Ls\n",
        "\n",
        "        return dydt\n",
        "\n",
        "class NeuralODE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralODE, self).__init__()\n",
        "        ## equivalent to transformations into the transformations video->tensor with the 7 parameters\n",
        "        self.fc1 = nn.Linear(4, 64).double()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 7).double()\n",
        "        self.norm1 = Normalizer()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## next two lines would be the transformation 3DCNN: video -> 7 parameters; pars = the 7 parameters normalized\n",
        "        pars = self.norm1(self.fc2(self.relu(self.fc1(x)))) #pars: (Tc, startv, emax, emin, rm, ra, Vd)\n",
        "\n",
        "        y0 = torch.stack([pars[1], pars[1] * pars[3], torch.tensor(75.), torch.tensor(75.), torch.tensor(0.)], dim=0) #y0 = (startv, startv * emin, 75., 75., 0.)\n",
        "        #y0 = torch.stack([pars[1], pars[1] * pars[3], torch.full((400,), 75.), torch.full((400,), 75.), torch.full((400,), 0.)], dim=0) #y0 = (startv, startv * emin, 75., 75., 0.)\n",
        "\n",
        "        func = ODEFunc(pars[0], pars[2], pars[3], pars[4], pars[5], pars[6])\n",
        "\n",
        "        '''\n",
        "        # using total time indep of n cycles:\n",
        "        time_interval = torch.linspace(0., self.tot_time, int(self.tot_time * self.n_sec)).to(device)\n",
        "        pred_y = odeint(func, y0, time_interval, method='euler', atol=1e-6, rtol=1e-6).to(device) #method='dopri5'\n",
        "        ved = pred_y[int(int(self.tot_time / pars[0]) * pars[0] * self.n_sec), 0] + pars[6]\n",
        "        ves = pred_y[int(((int(self.tot_time / pars[0]) - 0.85) * pars[0] + 0.2) * self.n_sec), 0] + pars[6]\n",
        "        '''\n",
        "        #times of ved, ves after N cycles:\n",
        "        N = 15\n",
        "        time_interval = torch.tensor([0., pars[0] * N, pars[0] * (N+0.15) + 0.2 ])\n",
        "        options = {'step_size': 0.0001}\n",
        "        pred_y = odeint(func, y0, time_interval, method='euler', atol=1e-6, rtol=1e-6, options=options) #method='dopri5'\n",
        "        ved = pred_y[1, 0] + pars[6]\n",
        "        ves = pred_y[2, 0] + pars[6]\n",
        "        with torch.no_grad(): print(pred_y, \"a\", ved, ves)\n",
        "        '''\n",
        "        #using outputs at all times and selecting the specific time frame after integration:\n",
        "        with torch.no_grad(): time_interval = torch.linspace(0, pars[0]*N, int(60000*N)) #spaced numbers over interval (start, stop, number_of_steps), 60000 time instances for each heart cycle\n",
        "        #changed to 60000 for having integer positions for Tmax\n",
        "        pred_y = odeint(func, y0, time_interval, method='euler', atol=1e-6, rtol=1e-6, options=options) #method='dopri5'\n",
        "        ved = pred_y[(N-1)*60000, 0] + pars[6]\n",
        "        ves = pred_y[200*int(60/pars[0])+9000+(N-1)*60000, 0] + pars[6]\n",
        "        '''\n",
        "        ef = (ved - ves) / ved * 100.\n",
        "\n",
        "        # to check that it gets the correct ved, ves:\n",
        "        #with torch.no_grad(): x, v1, v2, eff = pvloop_simulator(pars[0].item(), pars[1].item(), pars[2].item(), pars[3].item(), pars[4].item(), pars[5].item(), pars[6].item(), 30, False, False, False)\n",
        "        #print(v1, v2)\n",
        "\n",
        "        return ved, ves, ef\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train neural ode with 1 fixed input:"
      ],
      "metadata": {
        "id": "NMGVrqINV4ZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ii = 0\n",
        "model = NeuralODE() #42.5\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=1e-3)\n",
        "\n",
        "losses = []\n",
        "\n",
        "# get fixed input and fixed label:\n",
        "X, ved, ves, ef = pvloop_simulator(1.3, 50., 1.7, 0.05, 0.05, 0.02, 10., 70, False, False, False)\n",
        "\n",
        "for itr in range(1):\n",
        "\n",
        "    ## TO CHANGE: change the next line to have input = processed video / batch viewed as torch tensor\n",
        "    input = torch.tensor([X[0], X[1], X[2], X[3]])\n",
        "\n",
        "    ## TO CHANGE: change the next line to have true_ved, true_ves, true_ef = true labels of the video / batch\n",
        "    true_ved, true_ves, true_ef = torch.tensor(ved), torch.tensor(ves), torch.tensor(ef)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    pred_ved, pred_ves, pred_ef = model(input)\n",
        "    loss = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    if itr % 5 == 0:\n",
        "      print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss.item()))\n",
        "\n",
        "      #if itr % 50 == 0:\n",
        "      plt.plot(np.arange(len(losses)), losses)\n",
        "      plt.xlabel(\"Iteration\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "f7FbMxo6V1Ld",
        "outputId": "783be5f2-8119-472b-920b-8a9ee056ac8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[279.3914,   5.5878,  75.0000,  75.0000,   0.0000],\n",
            "        [157.7295,   6.9691, 156.9585, 157.2420,   8.2759],\n",
            "        [106.2208,  14.1895, 170.7464, 174.7563, 189.2869]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(161.7295, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(110.2208, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "Iter 0000 | Total Loss 144.449096\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the NN interpolator-based model:"
      ],
      "metadata": {
        "id": "zw6WARcBVyTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class Interpolator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(6, 256).double()\n",
        "        self.fc2 = nn.Linear(256, 2).double()\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = torch.relu(self.fc1(z))\n",
        "        z = self.fc2(z)\n",
        "        return z\n",
        "\n",
        "net = Interpolator()\n",
        "weights_path = '/content/drive/My Drive/net_weights__weight.pt'\n",
        "net.load_state_dict(torch.load(weights_path, map_location=torch.device('cpu')))\n",
        "\n",
        "for name, param in net.named_parameters():\n",
        "    print(f\"Parameter {name} is on device: {param.device}\")\n",
        "\n",
        "for param in net.parameters(): param.requires_grad = False\n",
        "\n",
        "class Normalizer1(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lower = torch.tensor([0.4, 0., 0.5, 0.02, 0.005, 0.0001], dtype=torch.float32)\n",
        "        self.upper = torch.tensor([1.7, 280., 3.5, 0.1, 0.1, 0.25], dtype=torch.float32)\n",
        "    def forward(self, inputs):\n",
        "        return torch.sigmoid(inputs) * (self.upper - self.lower) + self.lower\n",
        "\n",
        "class Normalizer2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.lower = torch.tensor([4.], dtype=torch.float32)\n",
        "        self.upper = torch.tensor([25.], dtype=torch.float32)\n",
        "    def forward(self, inputs):\n",
        "        return torch.sigmoid(inputs) * (self.upper - self.lower) + self.lower\n",
        "\n",
        "class Model2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model2, self).__init__()\n",
        "\n",
        "        ## equivalent to transformations into the transformations video->tensor with the 7 parameters\n",
        "        self.fc1 = nn.Linear(4, 64).double()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc21 = nn.Linear(64, 6).double()\n",
        "        self.fc22 = nn.Linear(64, 1).double()\n",
        "        self.norm1 = Normalizer1()\n",
        "        self.norm2 = Normalizer2()\n",
        "        self.interpolator = net\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        ## next two lines would be the transformation 3DCNN: video -> 7 parameters; pars = the 7 parameters normalized\n",
        "        x = self.relu(self.fc1(x))\n",
        "        pars = self.norm1(self.fc21(x)) #pars: (Tc, startv, emax, emin, rm, ra)\n",
        "        Vd = self.norm2(self.fc22(x))\n",
        "\n",
        "        ved, ves = self.interpolator(pars)\n",
        "        ved = ved + Vd - 4.\n",
        "        ves = ves + Vd - 4.\n",
        "        with torch.no_grad(): print(ved+Vd, ves+Vd)\n",
        "\n",
        "        return ved, ves, (ved - ves) / ved * 100.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_ziznoyb_0K",
        "outputId": "7f46ac86-a707-46ae-e416-a2ba7ec8c940"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Parameter fc1.weight is on device: cpu\n",
            "Parameter fc1.bias is on device: cpu\n",
            "Parameter fc2.weight is on device: cpu\n",
            "Parameter fc2.bias is on device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a fixed input (X: input, = LV volumes at 0.2Tc, 0.4Tc, 0.6Tc, 0.8Tc) and fixed label (ef: label)"
      ],
      "metadata": {
        "id": "YeIDswzTL3K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, ved, ves, ef = pvloop_simulator(1.3, 50., 1.7, 0.05, 0.05, 0.02, 10., 70, False, False, False)"
      ],
      "metadata": {
        "id": "jBUkX2msq5rW"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train both models on same fixed input:"
      ],
      "metadata": {
        "id": "fMew69Htb9DD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = NeuralODE()\n",
        "model2 = Model2()\n",
        "optimizer1 = optim.RMSprop(model1.parameters(), lr=1e-4)\n",
        "optimizer2 = optim.RMSprop(model2.parameters(), lr=1e-3)\n",
        "losses1 = []\n",
        "losses2 = []\n",
        "\n",
        "for name, param in model1.named_parameters():\n",
        "    print(f\"Parameter {name} is on device: {param.device}\")\n",
        "\n",
        "for itr in range(150):\n",
        "\n",
        "    ## TO CHANGE: change the next line to have input = processed video / batch viewed as torch tensor\n",
        "\n",
        "    ## TO CHANGE: change the next line to have true_ved, true_ves, true_ef = true labels of the video / batch\n",
        "    true_ved, true_ves, true_ef = torch.tensor(ved), torch.tensor(ves), torch.tensor(ef)\n",
        "\n",
        "    input = torch.tensor([X[0], X[1], X[2], X[3]])\n",
        "    print(input)\n",
        "    #model1:\n",
        "    optimizer1.zero_grad()\n",
        "    pred_ved, pred_ves, pred_ef = model1(input)\n",
        "    #loss1 = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\n",
        "    loss1 = torch.abs(pred_ef - true_ef)\n",
        "    loss1.backward()\n",
        "    optimizer1.step()\n",
        "    losses1.append(loss1.item())\n",
        "\n",
        "    #model2:\n",
        "    optimizer2.zero_grad()\n",
        "    pred_ved, pred_ves, pred_ef = model2(input)\n",
        "    #loss2 = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\n",
        "    loss2 = torch.abs(pred_ef - true_ef)\n",
        "    loss2.backward()\n",
        "    optimizer2.step()\n",
        "    losses2.append(loss2.item())\n",
        "\n",
        "    if itr == 30: optimizer2 = optim.RMSprop(model2.parameters(), lr=1e-4)\n",
        "    if itr == 60: optimizer2 = optim.RMSprop(model2.parameters(), lr=1e-5)\n",
        "\n",
        "    if itr % 5 == 0:\n",
        "      #print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss1.item()))\n",
        "      plt.plot(np.arange(len(losses1)), losses1, label='Adjoint odeint model')\n",
        "      plt.plot(np.arange(len(losses2)), losses2, label='NN-interpolator model')\n",
        "      plt.xlabel(\"Iteration\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.legend(loc='upper right', framealpha=1)\n",
        "      plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "szRczgiSV1E5",
        "outputId": "15db8986-9459-48aa-b9d3-23e6f7b556f6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter fc1.weight is on device: cpu\n",
            "Parameter fc1.bias is on device: cpu\n",
            "Parameter fc2.weight is on device: cpu\n",
            "Parameter fc2.bias is on device: cpu\n",
            "tensor([62.7993, 47.8942, 75.9630, 90.2334], dtype=torch.float64)\n",
            "tensor([[1.9592e-04, 3.9192e-06, 7.5000e+01, 7.5000e+01, 0.0000e+00],\n",
            "        [4.9762e+01, 6.2320e+00, 2.0258e+01, 2.0290e+01, 1.0492e+00],\n",
            "        [4.7301e+01, 6.5302e+00, 2.0963e+01, 2.2935e+01, 5.8798e+01]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(74.3312, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(71.8699, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([129.5871], dtype=torch.float64) tensor([100.5798], dtype=torch.float64)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([62.7993, 47.8942, 75.9630, 90.2334], dtype=torch.float64)\n",
            "tensor([[7.8503e-04, 1.5704e-05, 7.5000e+01, 7.5000e+01, 0.0000e+00],\n",
            "        [4.9681e+01, 6.2374e+00, 2.0300e+01, 2.0331e+01, 1.0464e+00],\n",
            "        [4.7200e+01, 6.5362e+00, 2.1017e+01, 2.2984e+01, 5.9086e+01]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(72.3402, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(69.8593, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([286.7802], dtype=torch.float64) tensor([104.5384], dtype=torch.float64)\n",
            "tensor([62.7993, 47.8942, 75.9630, 90.2334], dtype=torch.float64)\n",
            "tensor([[3.0835e-03, 6.1683e-05, 7.5000e+01, 7.5000e+01, 0.0000e+00],\n",
            "        [4.9614e+01, 6.2421e+00, 2.0335e+01, 2.0365e+01, 1.0435e+00],\n",
            "        [4.7116e+01, 6.5413e+00, 2.1063e+01, 2.3025e+01, 5.9323e+01]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(65.7653, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(63.2676, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([287.0554], dtype=torch.float64) tensor([104.8136], dtype=torch.float64)\n",
            "tensor([62.7993, 47.8942, 75.9630, 90.2334], dtype=torch.float64)\n",
            "tensor([[1.1951e-02, 2.3907e-04, 7.5000e+01, 7.5000e+01, 0.0000e+00],\n",
            "        [4.9563e+01, 6.2463e+00, 2.0365e+01, 2.0394e+01, 1.0408e+00],\n",
            "        [4.7051e+01, 6.5460e+00, 2.1102e+01, 2.3060e+01, 5.9519e+01]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(57.7841, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(55.2721, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([287.0554], dtype=torch.float64) tensor([104.8136], dtype=torch.float64)\n",
            "tensor([62.7993, 47.8942, 75.9630, 90.2334], dtype=torch.float64)\n",
            "tensor([[4.1756e-02, 8.3539e-04, 7.5000e+01, 7.5000e+01, 0.0000e+00],\n",
            "        [4.9547e+01, 6.2503e+00, 2.0387e+01, 2.0416e+01, 1.0393e+00],\n",
            "        [4.7026e+01, 6.5503e+00, 2.1129e+01, 2.3085e+01, 5.9642e+01]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(55.1183, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(52.5976, dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([287.0553], dtype=torch.float64) tensor([104.8136], dtype=torch.float64)\n",
            "tensor([62.7993, 47.8942, 75.9630, 90.2334], dtype=torch.float64)\n",
            "tensor([[1.2827e-01, 2.5669e-03, 7.5000e+01, 7.5000e+01, 0.0000e+00],\n",
            "        [4.9578e+01, 6.2569e+00, 2.0411e+01, 2.0440e+01, 1.0395e+00],\n",
            "        [4.7051e+01, 6.5572e+00, 2.1156e+01, 2.3113e+01, 5.9736e+01]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(54.5416, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(52.0155, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-0f5dbdc27f1d>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#loss1 = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ef\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrue_ef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mlosses1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    286\u001b[0m             )\n\u001b[1;32m    287\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *grad_y)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# Run the augmented system backwards in time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 aug_state = odeint(\n\u001b[0m\u001b[1;32m    127\u001b[0m                     \u001b[0maugmented_dynamics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/fixed_grid.py\u001b[0m in \u001b[0;36m_step_func\u001b[0;34m(self, func, t0, dt, t1, y0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEXT\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_flat_to_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36maugmented_dynamics\u001b[0;34m(t, y_aug)\u001b[0m\n\u001b[1;32m     86\u001b[0m                     \u001b[0;31m# doesn't necessarily even exist if there is piecewise structure in time), so turning off gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                     \u001b[0;31m# wrt t here means we won't compute that if we don't need it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0mfunc_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt_requires_grad\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0;31m# Workaround for PyTorch bug #39784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-46d088c58019>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mdydt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mCr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mP_lv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdydt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mRs\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mdydt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mCa\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP_lv\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mCa\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdydt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mRc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train both models on a synthetic dataset of 400 patients (and 50 for testing) taken from the 450 results from the echonet dataset."
      ],
      "metadata": {
        "id": "to_EYMhqLfBw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create synthetic dataset:"
      ],
      "metadata": {
        "id": "lhGie6-Os01H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_patients = 450\n",
        "inputs = torch.zeros(n_patients, 4)\n",
        "labels = torch.zeros(n_patients, 3)"
      ],
      "metadata": {
        "id": "3kBoLovJsy_d"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs[0][1], inputs[0][2] = 1., 10.\n",
        "print(inputs[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAWEqX7oC7C9",
        "outputId": "490d1191-576e-4f42-a000-15ce5c2e1c03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.,  1., 10.,  0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get 450 random patients and create their inputs and labels:"
      ],
      "metadata": {
        "id": "o-on6Wi87tmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/drive/My Drive/'\n",
        "file = 'input_450patients_echonet.pt'\n",
        "inputs_dt = torch.load(output_path + file)\n",
        "file = 'labels_450patients_echonet.pt'\n",
        "labels_dt = torch.load(output_path + file)\n",
        "print(inputs_dt, labels_dt)\n",
        "\n",
        "for i in range(450):\n",
        "  inputs[i][0], inputs[i][1], inputs[i][2], inputs[i][3] = inputs_dt[i][0], inputs_dt[i][1], inputs_dt[i][2], inputs_dt[i][3]\n",
        "  labels[i][0], labels[i][1], labels[i][2] = labels_dt[i][0], labels_dt[i][1], labels_dt[i][2]"
      ],
      "metadata": {
        "id": "y4olGz30RE-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e17474e-9563-41b4-bca3-cb7cd388596c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 85.8130,  53.6109, 100.9342, 127.3723],\n",
            "        [ 86.4939,  54.5375, 103.0440, 130.5176],\n",
            "        [ 74.7540,  51.3572, 100.0706, 125.7604],\n",
            "        ...,\n",
            "        [ 81.2824,  52.7348, 101.2469, 127.7181],\n",
            "        [144.8227,  95.7740, 112.8991, 138.6498],\n",
            "        [ 73.4291,  52.3870, 101.9269, 128.3651]]) tensor([[144.3182,  55.4956,  61.5464],\n",
            "        [148.2538,  55.8099,  62.3552],\n",
            "        [142.4189,  50.2441,  64.7209],\n",
            "        ...,\n",
            "        [144.8031,  53.1772,  63.2762],\n",
            "        [154.8586, 100.6008,  35.0370],\n",
            "        [145.6347,  50.0136,  65.6582]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the data, train both models:"
      ],
      "metadata": {
        "id": "ZOH21CWkHcP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(inputs_dt.shape)"
      ],
      "metadata": {
        "id": "Z0HYQFaxWeUZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85821fc5-aa1a-450f-ab90-a1d062d51cfb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([450, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = NeuralODE()\n",
        "model2 = Model2()\n",
        "optimizer1 = optim.RMSprop(model1.parameters(), lr=1e-4)\n",
        "optimizer2 = optim.RMSprop(model2.parameters(), lr=1e-3)\n",
        "losses1 = []\n",
        "losses2 = []\n",
        "\n",
        "x_train = torch.zeros((400, 4))\n",
        "y_train = torch.zeros((400, 1))\n",
        "for i in range(400):\n",
        "  x_train[i][0], x_train[i][1], x_train[i][2], x_train[i][3] = inputs[i][0], inputs[i][1], inputs[i][2], inputs[i][3]\n",
        "  y_train[i][0] = labels[i][2]\n",
        "x_train = torch.tensor(x_train, dtype = torch.float64)\n",
        "y_train = torch.tensor(y_train, dtype = torch.float64)\n",
        "n_itrs = 400\n",
        "\n",
        "for itr in range(n_itrs):\n",
        "    ## TO CHANGE: change the next line to have input = processed video / batch viewed as torch tensor\n",
        "\n",
        "    ## TO CHANGE: change the next line to have true_ved, true_ves, true_ef = true labels of the video / batch\n",
        "    true_ved, true_ves, true_ef = torch.tensor(ved), torch.tensor(ves), torch.tensor(ef)\n",
        "\n",
        "    j = itr #random.randint(0,400)\n",
        "\n",
        "    optimizer1.zero_grad()\n",
        "    pred_ved, pred_ves, pred_ef = model1(x_train[j])\n",
        "    #loss1 = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\n",
        "    loss1 = torch.abs(pred_ef - y_train[j][0])\n",
        "    loss1.backward()\n",
        "    optimizer1.step()\n",
        "    losses1.append(loss1.item())\n",
        "\n",
        "    optimizer2.zero_grad()\n",
        "    #loss2 = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\n",
        "    pred_ved, pred_ves, pred_efs = model2(x_train[j])\n",
        "    loss2 = torch.abs(pred_efs - y_train[j][0])\n",
        "    loss2.backward()\n",
        "    optimizer2.step()\n",
        "    losses2.append(loss2.item())\n",
        "\n",
        "    if itr == 35: optimizer2 = optim.RMSprop(model2.parameters(), lr=1e-5)\n",
        "    if itr == 60: optimizer2 = optim.RMSprop(model2.parameters(), lr=1e-6)\n",
        "\n",
        "    if itr % 10 == 0 and itr>0:\n",
        "      #print('Iter {:04d} | Total Loss {:.6f}'.format(itr, loss1.item()))\n",
        "      plt.plot(np.arange(len(losses1)), losses1, label='Adjoint odeint model')\n",
        "      plt.plot(np.arange(len(losses2)), losses2, label='NN-interpolator model')\n",
        "      plt.xlabel(\"Iteration\")\n",
        "      plt.ylabel(\"Loss\")\n",
        "      plt.legend(loc='upper right', framealpha=1)\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "_jzm7HjiHZDA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "outputId": "e8c0bcf1-d0e1-4d82-bbfb-fc8a82556b5a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-65e04d52949f>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x_train = torch.tensor(x_train, dtype = torch.float64)\n",
            "<ipython-input-17-65e04d52949f>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train = torch.tensor(y_train, dtype = torch.float64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[279.9765,  27.9976,  75.0000,  75.0000,   0.0000],\n",
            "        [236.8438,  30.3773,  98.1561,  98.3082,   3.8538],\n",
            "        [ 68.1180,  40.6010, 185.5630, 191.9381, 187.1884]],\n",
            "       dtype=torch.float64, grad_fn=<OdeintAdjointMethodBackward>) a tensor(240.8438, dtype=torch.float64, grad_fn=<AddBackward0>) tensor(72.1180, dtype=torch.float64, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-65e04d52949f>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#loss1 = torch.mean(torch.abs(pred_ved - true_ved) + torch.abs(pred_ves - true_ves) + torch.abs(pred_ef - true_ef))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mloss1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_ef\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0moptimizer1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mlosses1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    286\u001b[0m             )\n\u001b[1;32m    287\u001b[0m         \u001b[0muser_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvjp_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvjp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbackward_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0muser_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_jvp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(ctx, *grad_y)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;31m# Run the augmented system backwards in time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 aug_state = odeint(\n\u001b[0m\u001b[1;32m    127\u001b[0m                     \u001b[0maugmented_dynamics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maug_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/odeint.py\u001b[0m in \u001b[0;36modeint\u001b[0;34m(func, y0, t, rtol, atol, method, options, event_fn)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mevent_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mevent_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate_until_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/solvers.py\u001b[0m in \u001b[0;36mintegrate\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_grid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mdy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/fixed_grid.py\u001b[0m in \u001b[0;36m_step_func\u001b[0;34m(self, func, t0, dt, t1, y0)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_step_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mf0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperturb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEXT\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturb\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mPerturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y, perturb)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;31m# Do nothing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_flat_to_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchdiffeq/_impl/adjoint.py\u001b[0m in \u001b[0;36maugmented_dynamics\u001b[0;34m(t, y_aug)\u001b[0m\n\u001b[1;32m     93\u001b[0m                     \u001b[0m_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_strided\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0madjoint_params\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                     vjp_t, vjp_y, *vjp_params = torch.autograd.grad(\n\u001b[0m\u001b[1;32m     96\u001b[0m                         \u001b[0mfunc_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madjoint_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0madj_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                         \u001b[0mallow_unused\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    392\u001b[0m         )\n\u001b[1;32m    393\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         result = Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    395\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(itr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoGLHNghBIlF",
        "outputId": "f6c61526-ee5c-44ea-f496-f85c05194878"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    }
  ]
}